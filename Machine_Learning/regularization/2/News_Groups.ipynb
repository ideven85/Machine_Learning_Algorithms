{
 "cells": [
  {
   "cell_type": "code",
   "id": "191d7499-a534-4a79-bf2e-4e3c5a3d1718",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T20:45:05.650469Z",
     "iopub.status.busy": "2025-02-13T20:45:05.649806Z",
     "iopub.status.idle": "2025-02-13T20:45:05.655168Z",
     "shell.execute_reply": "2025-02-13T20:45:05.654667Z",
     "shell.execute_reply.started": "2025-02-13T20:45:05.650436Z"
    },
    "ExecuteTime": {
     "end_time": "2025-02-16T22:21:04.996170Z",
     "start_time": "2025-02-16T22:21:04.994368Z"
    }
   },
   "source": [
    "def main():\n",
    "    print(\"Hi\")\n",
    "\n",
    "\n",
    "main()\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "cd680302-5d9d-498e-9c7f-df234fcc1185",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2025-02-13T20:46:15.659162Z",
     "iopub.status.busy": "2025-02-13T20:46:15.658676Z",
     "iopub.status.idle": "2025-02-13T20:46:15.663637Z",
     "shell.execute_reply": "2025-02-13T20:46:15.662783Z",
     "shell.execute_reply.started": "2025-02-13T20:46:15.659130Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-02-16T22:21:12.892663Z",
     "start_time": "2025-02-16T22:21:05.135577Z"
    }
   },
   "source": [
    "%load_ext chapyter\n",
    "%chat -m gpt-4-0613"
   ],
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'guidance' has no attribute 'Program'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mget_ipython\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_line_magic\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mload_ext\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mchapyter\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m get_ipython()\u001B[38;5;241m.\u001B[39mrun_line_magic(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mchat\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m-m gpt-4-0613\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/.virtualenvs/Machine_Learning_Algorithms/lib/python3.12/site-packages/IPython/core/interactiveshell.py:2482\u001B[0m, in \u001B[0;36mInteractiveShell.run_line_magic\u001B[0;34m(self, magic_name, line, _stack_depth)\u001B[0m\n\u001B[1;32m   2480\u001B[0m     kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlocal_ns\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_local_scope(stack_depth)\n\u001B[1;32m   2481\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuiltin_trap:\n\u001B[0;32m-> 2482\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2484\u001B[0m \u001B[38;5;66;03m# The code below prevents the output from being displayed\u001B[39;00m\n\u001B[1;32m   2485\u001B[0m \u001B[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001B[39;00m\n\u001B[1;32m   2486\u001B[0m \u001B[38;5;66;03m# when the last Python token in the expression is a ';'.\u001B[39;00m\n\u001B[1;32m   2487\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(fn, magic\u001B[38;5;241m.\u001B[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001B[38;5;28;01mFalse\u001B[39;00m):\n",
      "File \u001B[0;32m~/.virtualenvs/Machine_Learning_Algorithms/lib/python3.12/site-packages/IPython/core/magics/extension.py:33\u001B[0m, in \u001B[0;36mExtensionMagics.load_ext\u001B[0;34m(self, module_str)\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m module_str:\n\u001B[1;32m     32\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m UsageError(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMissing module name.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 33\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshell\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mextension_manager\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_extension\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodule_str\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     35\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m res \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124malready loaded\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m     36\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m extension is already loaded. To reload it, use:\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m module_str)\n",
      "File \u001B[0;32m~/.virtualenvs/Machine_Learning_Algorithms/lib/python3.12/site-packages/IPython/core/extensions.py:62\u001B[0m, in \u001B[0;36mExtensionManager.load_extension\u001B[0;34m(self, module_str)\u001B[0m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Load an IPython extension by its module name.\u001B[39;00m\n\u001B[1;32m     56\u001B[0m \n\u001B[1;32m     57\u001B[0m \u001B[38;5;124;03mReturns the string \"already loaded\" if the extension is already loaded,\u001B[39;00m\n\u001B[1;32m     58\u001B[0m \u001B[38;5;124;03m\"no load function\" if the module doesn't have a load_ipython_extension\u001B[39;00m\n\u001B[1;32m     59\u001B[0m \u001B[38;5;124;03mfunction, or None if it succeeded.\u001B[39;00m\n\u001B[1;32m     60\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     61\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 62\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_load_extension\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodule_str\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mModuleNotFoundError\u001B[39;00m:\n\u001B[1;32m     64\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m module_str \u001B[38;5;129;01min\u001B[39;00m BUILTINS_EXTS:\n",
      "File \u001B[0;32m~/.virtualenvs/Machine_Learning_Algorithms/lib/python3.12/site-packages/IPython/core/extensions.py:79\u001B[0m, in \u001B[0;36mExtensionManager._load_extension\u001B[0;34m(self, module_str)\u001B[0m\n\u001B[1;32m     77\u001B[0m     mod \u001B[38;5;241m=\u001B[39m import_module(module_str)\n\u001B[1;32m     78\u001B[0m mod \u001B[38;5;241m=\u001B[39m sys\u001B[38;5;241m.\u001B[39mmodules[module_str]\n\u001B[0;32m---> 79\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_load_ipython_extension\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmod\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m     80\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloaded\u001B[38;5;241m.\u001B[39madd(module_str)\n\u001B[1;32m     81\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/.virtualenvs/Machine_Learning_Algorithms/lib/python3.12/site-packages/IPython/core/extensions.py:129\u001B[0m, in \u001B[0;36mExtensionManager._call_load_ipython_extension\u001B[0;34m(self, mod)\u001B[0m\n\u001B[1;32m    127\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_call_load_ipython_extension\u001B[39m(\u001B[38;5;28mself\u001B[39m, mod):\n\u001B[1;32m    128\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(mod, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mload_ipython_extension\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m--> 129\u001B[0m         \u001B[43mmod\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_ipython_extension\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshell\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    130\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m~/.virtualenvs/Machine_Learning_Algorithms/lib/python3.12/site-packages/chapyter/__init__.py:14\u001B[0m, in \u001B[0;36mload_ipython_extension\u001B[0;34m(ipython)\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mload_ipython_extension\u001B[39m(ipython) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m---> 14\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmagic\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m load_ipython_extension\n\u001B[1;32m     16\u001B[0m     load_ipython_extension(ipython)\n",
      "File \u001B[0;32m~/.virtualenvs/Machine_Learning_Algorithms/lib/python3.12/site-packages/chapyter/magic.py:25\u001B[0m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtraitlets\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Bool, Dict, Instance, Unicode, default, observe  \u001B[38;5;66;03m# noqa\u001B[39;00m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtraitlets\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mconfig\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mloader\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Config\n\u001B[0;32m---> 25\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mprograms\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     26\u001B[0m     _DEFAULT_CHATONLY_PROGRAM,\n\u001B[1;32m     27\u001B[0m     _DEFAULT_HISTORY_PROGRAM,\n\u001B[1;32m     28\u001B[0m     _DEFAULT_PROGRAM,\n\u001B[1;32m     29\u001B[0m     ChapyterAgentProgram,\n\u001B[1;32m     30\u001B[0m )\n\u001B[1;32m     32\u001B[0m logger \u001B[38;5;241m=\u001B[39m logging\u001B[38;5;241m.\u001B[39mgetLogger(\u001B[38;5;18m__name__\u001B[39m)\n\u001B[1;32m     34\u001B[0m _DEFAULT_PROGRAM_NAME \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_default\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[0;32m~/.virtualenvs/Machine_Learning_Algorithms/lib/python3.12/site-packages/chapyter/programs.py:16\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mIPython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01minteractiveshell\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m InteractiveShell\n\u001B[1;32m      8\u001B[0m __all__ \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m      9\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mChapyterAgentProgram\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     10\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_DEFAULT_PROGRAM\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_DEFAULT_HISTORY_PROGRAM\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     12\u001B[0m ]\n\u001B[1;32m     15\u001B[0m \u001B[38;5;129;43m@dataclasses\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataclass\u001B[49m\n\u001B[0;32m---> 16\u001B[0m \u001B[38;5;28;43;01mclass\u001B[39;49;00m\u001B[38;5;250;43m \u001B[39;49m\u001B[38;5;21;43;01mChapyterAgentProgram\u001B[39;49;00m\u001B[43m:\u001B[49m\n\u001B[1;32m     17\u001B[0m \u001B[43m    \u001B[49m\u001B[43mguidance_program\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mguidance\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mProgram\u001B[49m\n\u001B[1;32m     18\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpre_call_hooks\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mOptional\u001B[49m\u001B[43m[\u001B[49m\u001B[43mDict\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mCallable\u001B[49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\n",
      "File \u001B[0;32m~/.virtualenvs/Machine_Learning_Algorithms/lib/python3.12/site-packages/chapyter/programs.py:17\u001B[0m, in \u001B[0;36mChapyterAgentProgram\u001B[0;34m()\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;129m@dataclasses\u001B[39m\u001B[38;5;241m.\u001B[39mdataclass\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mChapyterAgentProgram\u001B[39;00m:\n\u001B[0;32m---> 17\u001B[0m     guidance_program: \u001B[43mguidance\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mProgram\u001B[49m\n\u001B[1;32m     18\u001B[0m     pre_call_hooks: Optional[Dict[\u001B[38;5;28mstr\u001B[39m, Callable]]\n\u001B[1;32m     19\u001B[0m     post_call_hooks: Optional[Dict[\u001B[38;5;28mstr\u001B[39m, Callable]]\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'guidance' has no attribute 'Program'"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5312f78-53ed-4fdd-b2c5-7c46dc1fca5a",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2025-02-13T20:46:39.752128Z",
     "iopub.status.busy": "2025-02-13T20:46:39.751479Z",
     "iopub.status.idle": "2025-02-13T20:46:39.757600Z",
     "shell.execute_reply": "2025-02-13T20:46:39.756157Z",
     "shell.execute_reply.started": "2025-02-13T20:46:39.752061Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Cell magic `%%chat` not found.\n"
     ]
    }
   ],
   "source": [
    "%%chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b1f3ce9-5cbd-4916-9c4a-bea500133729",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2025-02-13T20:47:04.107837Z",
     "iopub.status.busy": "2025-02-13T20:47:04.107368Z",
     "iopub.status.idle": "2025-02-13T20:47:04.111275Z",
     "shell.execute_reply": "2025-02-13T20:47:04.110784Z",
     "shell.execute_reply.started": "2025-02-13T20:47:04.107809Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def factorial(n):\n",
    "    return 1 if n < 2 else n * factorial(n - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df9ab54c-47c4-44f4-86b2-366dd1a7ba94",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2025-02-13T20:47:27.010464Z",
     "iopub.status.busy": "2025-02-13T20:47:27.009988Z",
     "iopub.status.idle": "2025-02-13T20:47:28.763614Z",
     "shell.execute_reply": "2025-02-13T20:47:28.763331Z",
     "shell.execute_reply.started": "2025-02-13T20:47:27.010438Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212 μs ± 368 ns per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit [factorial(x) for x in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ec11d40-8bf0-4647-8025-c20768094ac6",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2025-02-13T20:53:37.530382Z",
     "iopub.status.busy": "2025-02-13T20:53:37.529863Z",
     "iopub.status.idle": "2025-02-13T20:53:37.753076Z",
     "shell.execute_reply": "2025-02-13T20:53:37.752790Z",
     "shell.execute_reply.started": "2025-02-13T20:53:37.530354Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6e17572-3127-4c66-92bd-f008bd783d79",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2025-02-13T20:53:37.989906Z",
     "iopub.status.busy": "2025-02-13T20:53:37.989327Z",
     "iopub.status.idle": "2025-02-13T20:53:38.381095Z",
     "shell.execute_reply": "2025-02-13T20:53:38.380839Z",
     "shell.execute_reply.started": "2025-02-13T20:53:37.989877Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f24cc57-5bb7-4253-894e-262201d83f62",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2025-02-13T20:53:38.731424Z",
     "iopub.status.busy": "2025-02-13T20:53:38.730778Z",
     "iopub.status.idle": "2025-02-13T20:53:38.845530Z",
     "shell.execute_reply": "2025-02-13T20:53:38.845071Z",
     "shell.execute_reply.started": "2025-02-13T20:53:38.731398Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "news = fetch_20newsgroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf016fdf-830c-404e-9678-71627c74027b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "730ee7ca-b3ab-463d-9dcd-0dbbbd8ce8ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T20:48:56.378655Z",
     "iopub.status.busy": "2025-02-13T20:48:56.378150Z",
     "iopub.status.idle": "2025-02-13T20:48:56.383215Z",
     "shell.execute_reply": "2025-02-13T20:48:56.382674Z",
     "shell.execute_reply.started": "2025-02-13T20:48:56.378626Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _20newsgroups_dataset:\n",
      "\n",
      "The 20 newsgroups text dataset\n",
      "------------------------------\n",
      "\n",
      "The 20 newsgroups dataset comprises around 18000 newsgroups posts on\n",
      "20 topics split in two subsets: one for training (or development)\n",
      "and the other one for testing (or for performance evaluation). The split\n",
      "between the train and test set is based upon a messages posted before\n",
      "and after a specific date.\n",
      "\n",
      "This module contains two loaders. The first one,\n",
      ":func:`sklearn.datasets.fetch_20newsgroups`,\n",
      "returns a list of the raw texts that can be fed to text feature\n",
      "extractors such as :class:`~sklearn.feature_extraction.text.CountVectorizer`\n",
      "with custom parameters so as to extract feature vectors.\n",
      "The second one, :func:`sklearn.datasets.fetch_20newsgroups_vectorized`,\n",
      "returns ready-to-use features, i.e., it is not necessary to use a feature\n",
      "extractor.\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "=================   ==========\n",
      "Classes                     20\n",
      "Samples total            18846\n",
      "Dimensionality               1\n",
      "Features                  text\n",
      "=================   ==========\n",
      "\n",
      ".. dropdown:: Usage\n",
      "\n",
      "  The :func:`sklearn.datasets.fetch_20newsgroups` function is a data\n",
      "  fetching / caching functions that downloads the data archive from\n",
      "  the original `20 newsgroups website <http://people.csail.mit.edu/jrennie/20Newsgroups/>`__,\n",
      "  extracts the archive contents\n",
      "  in the ``~/scikit_learn_data/20news_home`` folder and calls the\n",
      "  :func:`sklearn.datasets.load_files` on either the training or\n",
      "  testing set folder, or both of them::\n",
      "\n",
      "    >>> from sklearn.datasets import fetch_20newsgroups\n",
      "    >>> newsgroups_train = fetch_20newsgroups(subset='train')\n",
      "\n",
      "    >>> from pprint import pprint\n",
      "    >>> pprint(list(newsgroups_train.target_names))\n",
      "    ['alt.atheism',\n",
      "     'comp.graphics',\n",
      "     'comp.os.ms-windows.misc',\n",
      "     'comp.sys.ibm.pc.hardware',\n",
      "     'comp.sys.mac.hardware',\n",
      "     'comp.windows.x',\n",
      "     'misc.forsale',\n",
      "     'rec.autos',\n",
      "     'rec.motorcycles',\n",
      "     'rec.sport.baseball',\n",
      "     'rec.sport.hockey',\n",
      "     'sci.crypt',\n",
      "     'sci.electronics',\n",
      "     'sci.med',\n",
      "     'sci.space',\n",
      "     'soc.religion.christian',\n",
      "     'talk.politics.guns',\n",
      "     'talk.politics.mideast',\n",
      "     'talk.politics.misc',\n",
      "     'talk.religion.misc']\n",
      "\n",
      "  The real data lies in the ``filenames`` and ``target`` attributes. The target\n",
      "  attribute is the integer index of the category::\n",
      "\n",
      "    >>> newsgroups_train.filenames.shape\n",
      "    (11314,)\n",
      "    >>> newsgroups_train.target.shape\n",
      "    (11314,)\n",
      "    >>> newsgroups_train.target[:10]\n",
      "    array([ 7,  4,  4,  1, 14, 16, 13,  3,  2,  4])\n",
      "\n",
      "  It is possible to load only a sub-selection of the categories by passing the\n",
      "  list of the categories to load to the\n",
      "  :func:`sklearn.datasets.fetch_20newsgroups` function::\n",
      "\n",
      "    >>> cats = ['alt.atheism', 'sci.space']\n",
      "    >>> newsgroups_train = fetch_20newsgroups(subset='train', categories=cats)\n",
      "\n",
      "    >>> list(newsgroups_train.target_names)\n",
      "    ['alt.atheism', 'sci.space']\n",
      "    >>> newsgroups_train.filenames.shape\n",
      "    (1073,)\n",
      "    >>> newsgroups_train.target.shape\n",
      "    (1073,)\n",
      "    >>> newsgroups_train.target[:10]\n",
      "    array([0, 1, 1, 1, 0, 1, 1, 0, 0, 0])\n",
      "\n",
      ".. dropdown:: Converting text to vectors\n",
      "\n",
      "  In order to feed predictive or clustering models with the text data,\n",
      "  one first need to turn the text into vectors of numerical values suitable\n",
      "  for statistical analysis. This can be achieved with the utilities of the\n",
      "  ``sklearn.feature_extraction.text`` as demonstrated in the following\n",
      "  example that extract `TF-IDF <https://en.wikipedia.org/wiki/Tf-idf>`__ vectors\n",
      "  of unigram tokens from a subset of 20news::\n",
      "\n",
      "    >>> from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "    >>> categories = ['alt.atheism', 'talk.religion.misc',\n",
      "    ...               'comp.graphics', 'sci.space']\n",
      "    >>> newsgroups_train = fetch_20newsgroups(subset='train',\n",
      "    ...                                       categories=categories)\n",
      "    >>> vectorizer = TfidfVectorizer()\n",
      "    >>> vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
      "    >>> vectors.shape\n",
      "    (2034, 34118)\n",
      "\n",
      "  The extracted TF-IDF vectors are very sparse, with an average of 159 non-zero\n",
      "  components by sample in a more than 30000-dimensional space\n",
      "  (less than .5% non-zero features)::\n",
      "\n",
      "    >>> vectors.nnz / float(vectors.shape[0])\n",
      "    159.01327...\n",
      "\n",
      "  :func:`sklearn.datasets.fetch_20newsgroups_vectorized` is a function which\n",
      "  returns ready-to-use token counts features instead of file names.\n",
      "\n",
      ".. dropdown:: Filtering text for more realistic training\n",
      "\n",
      "  It is easy for a classifier to overfit on particular things that appear in the\n",
      "  20 Newsgroups data, such as newsgroup headers. Many classifiers achieve very\n",
      "  high F-scores, but their results would not generalize to other documents that\n",
      "  aren't from this window of time.\n",
      "\n",
      "  For example, let's look at the results of a multinomial Naive Bayes classifier,\n",
      "  which is fast to train and achieves a decent F-score::\n",
      "\n",
      "    >>> from sklearn.naive_bayes import MultinomialNB\n",
      "    >>> from sklearn import metrics\n",
      "    >>> newsgroups_test = fetch_20newsgroups(subset='test',\n",
      "    ...                                      categories=categories)\n",
      "    >>> vectors_test = vectorizer.transform(newsgroups_test.data)\n",
      "    >>> clf = MultinomialNB(alpha=.01)\n",
      "    >>> clf.fit(vectors, newsgroups_train.target)\n",
      "    MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
      "\n",
      "    >>> pred = clf.predict(vectors_test)\n",
      "    >>> metrics.f1_score(newsgroups_test.target, pred, average='macro')\n",
      "    0.88213...\n",
      "\n",
      "  (The example :ref:`sphx_glr_auto_examples_text_plot_document_classification_20newsgroups.py` shuffles\n",
      "  the training and test data, instead of segmenting by time, and in that case\n",
      "  multinomial Naive Bayes gets a much higher F-score of 0.88. Are you suspicious\n",
      "  yet of what's going on inside this classifier?)\n",
      "\n",
      "  Let's take a look at what the most informative features are:\n",
      "\n",
      "    >>> import numpy as np\n",
      "    >>> def show_top10(classifier, vectorizer, categories):\n",
      "    ...     feature_names = vectorizer.get_feature_names_out()\n",
      "    ...     for i, category in enumerate(categories):\n",
      "    ...         top10 = np.argsort(classifier.coef_[i])[-10:]\n",
      "    ...         print(\"%s: %s\" % (category, \" \".join(feature_names[top10])))\n",
      "    ...\n",
      "    >>> show_top10(clf, vectorizer, newsgroups_train.target_names)\n",
      "    alt.atheism: edu it and in you that is of to the\n",
      "    comp.graphics: edu in graphics it is for and of to the\n",
      "    sci.space: edu it that is in and space to of the\n",
      "    talk.religion.misc: not it you in is that and to of the\n",
      "\n",
      "\n",
      "  You can now see many things that these features have overfit to:\n",
      "\n",
      "  - Almost every group is distinguished by whether headers such as\n",
      "    ``NNTP-Posting-Host:`` and ``Distribution:`` appear more or less often.\n",
      "  - Another significant feature involves whether the sender is affiliated with\n",
      "    a university, as indicated either by their headers or their signature.\n",
      "  - The word \"article\" is a significant feature, based on how often people quote\n",
      "    previous posts like this: \"In article [article ID], [name] <[e-mail address]>\n",
      "    wrote:\"\n",
      "  - Other features match the names and e-mail addresses of particular people who\n",
      "    were posting at the time.\n",
      "\n",
      "  With such an abundance of clues that distinguish newsgroups, the classifiers\n",
      "  barely have to identify topics from text at all, and they all perform at the\n",
      "  same high level.\n",
      "\n",
      "  For this reason, the functions that load 20 Newsgroups data provide a\n",
      "  parameter called **remove**, telling it what kinds of information to strip out\n",
      "  of each file. **remove** should be a tuple containing any subset of\n",
      "  ``('headers', 'footers', 'quotes')``, telling it to remove headers, signature\n",
      "  blocks, and quotation blocks respectively.\n",
      "\n",
      "    >>> newsgroups_test = fetch_20newsgroups(subset='test',\n",
      "    ...                                      remove=('headers', 'footers', 'quotes'),\n",
      "    ...                                      categories=categories)\n",
      "    >>> vectors_test = vectorizer.transform(newsgroups_test.data)\n",
      "    >>> pred = clf.predict(vectors_test)\n",
      "    >>> metrics.f1_score(pred, newsgroups_test.target, average='macro')\n",
      "    0.77310...\n",
      "\n",
      "  This classifier lost over a lot of its F-score, just because we removed\n",
      "  metadata that has little to do with topic classification.\n",
      "  It loses even more if we also strip this metadata from the training data:\n",
      "\n",
      "    >>> newsgroups_train = fetch_20newsgroups(subset='train',\n",
      "    ...                                       remove=('headers', 'footers', 'quotes'),\n",
      "    ...                                       categories=categories)\n",
      "    >>> vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
      "    >>> clf = MultinomialNB(alpha=.01)\n",
      "    >>> clf.fit(vectors, newsgroups_train.target)\n",
      "    MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
      "\n",
      "    >>> vectors_test = vectorizer.transform(newsgroups_test.data)\n",
      "    >>> pred = clf.predict(vectors_test)\n",
      "    >>> metrics.f1_score(newsgroups_test.target, pred, average='macro')\n",
      "    0.76995...\n",
      "\n",
      "  Some other classifiers cope better with this harder version of the task. Try the\n",
      "  :ref:`sphx_glr_auto_examples_model_selection_plot_grid_search_text_feature_extraction.py`\n",
      "  example with and without the `remove` option to compare the results.\n",
      "\n",
      ".. rubric:: Data Considerations\n",
      "\n",
      "The Cleveland Indians is a major league baseball team based in Cleveland,\n",
      "Ohio, USA. In December 2020, it was reported that \"After several months of\n",
      "discussion sparked by the death of George Floyd and a national reckoning over\n",
      "race and colonialism, the Cleveland Indians have decided to change their\n",
      "name.\" Team owner Paul Dolan \"did make it clear that the team will not make\n",
      "its informal nickname -- the Tribe -- its new team name.\" \"It's not going to\n",
      "be a half-step away from the Indians,\" Dolan said.\"We will not have a Native\n",
      "American-themed name.\"\n",
      "\n",
      "https://www.mlb.com/news/cleveland-indians-team-name-change\n",
      "\n",
      ".. rubric:: Recommendation\n",
      "\n",
      "- When evaluating text classifiers on the 20 Newsgroups data, you\n",
      "  should strip newsgroup-related metadata. In scikit-learn, you can do this\n",
      "  by setting ``remove=('headers', 'footers', 'quotes')``. The F-score will be\n",
      "  lower because it is more realistic.\n",
      "- This text dataset contains data which may be inappropriate for certain NLP\n",
      "  applications. An example is listed in the \"Data Considerations\" section\n",
      "  above. The challenge with using current text datasets in NLP for tasks such\n",
      "  as sentence completion, clustering, and other applications is that text\n",
      "  that is culturally biased and inflammatory will propagate biases. This\n",
      "  should be taken into consideration when using the dataset, reviewing the\n",
      "  output, and the bias should be documented.\n",
      "\n",
      ".. rubric:: Examples\n",
      "\n",
      "* :ref:`sphx_glr_auto_examples_model_selection_plot_grid_search_text_feature_extraction.py`\n",
      "* :ref:`sphx_glr_auto_examples_text_plot_document_classification_20newsgroups.py`\n",
      "* :ref:`sphx_glr_auto_examples_text_plot_hashing_vs_dict_vectorizer.py`\n",
      "* :ref:`sphx_glr_auto_examples_text_plot_document_clustering.py`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(news.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc3bb1a3-3c5f-46a3-abaa-086596d846ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T20:50:06.441128Z",
     "iopub.status.busy": "2025-02-13T20:50:06.440641Z",
     "iopub.status.idle": "2025-02-13T20:50:06.445783Z",
     "shell.execute_reply": "2025-02-13T20:50:06.445156Z",
     "shell.execute_reply.started": "2025-02-13T20:50:06.441100Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"News.md\", \"w\") as f:\n",
    "    f.write(news.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b307505c-070d-4376-a5b2-4296a35d9184",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2025-02-13T20:53:52.037757Z",
     "iopub.status.busy": "2025-02-13T20:53:52.037276Z",
     "iopub.status.idle": "2025-02-13T20:53:52.537424Z",
     "shell.execute_reply": "2025-02-13T20:53:52.537187Z",
     "shell.execute_reply.started": "2025-02-13T20:53:52.037731Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": ""
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fe4d654-4934-4226-9485-f21e5b183721",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T20:54:11.930750Z",
     "iopub.status.busy": "2025-02-13T20:54:11.930249Z",
     "iopub.status.idle": "2025-02-13T20:54:11.935127Z",
     "shell.execute_reply": "2025-02-13T20:54:11.934251Z",
     "shell.execute_reply.started": "2025-02-13T20:54:11.930721Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: %%chat is a cell magic, but the cell body is empty. Did you mean the line magic %chat (single %)?\n"
     ]
    }
   ],
   "source": ""
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3227be68-9ec8-4a65-920d-df2294a3efea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T20:54:33.761316Z",
     "iopub.status.busy": "2025-02-13T20:54:33.760835Z",
     "iopub.status.idle": "2025-02-13T20:54:43.613240Z",
     "shell.execute_reply": "2025-02-13T20:54:43.612772Z",
     "shell.execute_reply.started": "2025-02-13T20:54:33.761289Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/deven/Developer/Machine_Learning_Algorithms/.venv/lib/python3.12/site-packages/guidance/llms/_openai.py\", line 665, in __call__\n",
      "    out = await self.llm.caller(**call_args)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/deven/Developer/Machine_Learning_Algorithms/.venv/lib/python3.12/site-packages/guidance/llms/_openai.py\", line 348, in _library_call\n",
      "    prev_base = openai.api_base\n",
      "                ^^^^^^^^^^^^^^^\n",
      "AttributeError: module 'openai' has no attribute 'api_base'. Did you mean: 'api_type'?\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/deven/Developer/Machine_Learning_Algorithms/.venv/lib/python3.12/site-packages/guidance/_program_executor.py\", line 109, in run\n",
      "    await self.visit(self.parse_tree, VariableStack([self.program._variables], self))\n",
      "  File \"/Users/deven/Developer/Machine_Learning_Algorithms/.venv/lib/python3.12/site-packages/guidance/_program_executor.py\", line 559, in visit\n",
      "    visited_children.append(await self.visit(child, variable_stack, inner_next_node, inner_next_next_node, inner_prev_node, node, parent_node))\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/deven/Developer/Machine_Learning_Algorithms/.venv/lib/python3.12/site-packages/guidance/_program_executor.py\", line 524, in visit\n",
      "    command_output = await command_function(*positional_args, **named_args)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/deven/Developer/Machine_Learning_Algorithms/.venv/lib/python3.12/site-packages/guidance/library/_assistant.py\", line 13, in assistant\n",
      "    return await role(role_name=\"assistant\", hidden=hidden, _parser_context=_parser_context, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/deven/Developer/Machine_Learning_Algorithms/.venv/lib/python3.12/site-packages/guidance/library/_role.py\", line 17, in role\n",
      "    new_content += await parser.visit(\n",
      "                   ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/deven/Developer/Machine_Learning_Algorithms/.venv/lib/python3.12/site-packages/guidance/_program_executor.py\", line 559, in visit\n",
      "    visited_children.append(await self.visit(child, variable_stack, inner_next_node, inner_next_next_node, inner_prev_node, node, parent_node))\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/deven/Developer/Machine_Learning_Algorithms/.venv/lib/python3.12/site-packages/guidance/_program_executor.py\", line 559, in visit\n",
      "    visited_children.append(await self.visit(child, variable_stack, inner_next_node, inner_next_next_node, inner_prev_node, node, parent_node))\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/deven/Developer/Machine_Learning_Algorithms/.venv/lib/python3.12/site-packages/guidance/_program_executor.py\", line 266, in visit\n",
      "    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/deven/Developer/Machine_Learning_Algorithms/.venv/lib/python3.12/site-packages/guidance/_program_executor.py\", line 379, in visit\n",
      "    command_output = await command_function(*positional_args, **named_args)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/deven/Developer/Machine_Learning_Algorithms/.venv/lib/python3.12/site-packages/guidance/library/_gen.py\", line 140, in gen\n",
      "    gen_obj = await parser.llm_session(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/deven/Developer/Machine_Learning_Algorithms/.venv/lib/python3.12/site-packages/guidance/llms/_openai.py\", line 667, in __call__\n",
      "    except openai.error.RateLimitError:\n",
      "           ^^^^^^^^^^^^\n",
      "AttributeError: module 'openai' has no attribute 'error'\n",
      "\n",
      "Error in program:  module 'openai' has no attribute 'error'\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'code'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mget_ipython\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_cell_magic\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mchat\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[38;5;124;43mGenerate a dictionary that groups the files in the current folder based on their types\u001B[39;49m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Developer/Machine_Learning_Algorithms/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py:2543\u001B[0m, in \u001B[0;36mInteractiveShell.run_cell_magic\u001B[0;34m(self, magic_name, line, cell)\u001B[0m\n\u001B[1;32m   2541\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuiltin_trap:\n\u001B[1;32m   2542\u001B[0m     args \u001B[38;5;241m=\u001B[39m (magic_arg_s, cell)\n\u001B[0;32m-> 2543\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2545\u001B[0m \u001B[38;5;66;03m# The code below prevents the output from being displayed\u001B[39;00m\n\u001B[1;32m   2546\u001B[0m \u001B[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001B[39;00m\n\u001B[1;32m   2547\u001B[0m \u001B[38;5;66;03m# when the last Python token in the expression is a ';'.\u001B[39;00m\n\u001B[1;32m   2548\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(fn, magic\u001B[38;5;241m.\u001B[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001B[38;5;28;01mFalse\u001B[39;00m):\n",
      "File \u001B[0;32m~/Developer/Machine_Learning_Algorithms/.venv/lib/python3.12/site-packages/chapyter/magic.py:304\u001B[0m, in \u001B[0;36mChapyter.chat\u001B[0;34m(self, line, cell)\u001B[0m\n\u001B[1;32m    301\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m    302\u001B[0m current_message \u001B[38;5;241m=\u001B[39m cell\n\u001B[0;32m--> 304\u001B[0m program_out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute_chat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcurrent_message\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshell\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    305\u001B[0m execution_id \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshell\u001B[38;5;241m.\u001B[39mexecution_count\n\u001B[1;32m    306\u001B[0m program_out \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m# Assistant Code for Cell [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mexecution_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m]:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m program_out\n",
      "File \u001B[0;32m~/Developer/Machine_Learning_Algorithms/.venv/lib/python3.12/site-packages/chapyter/magic.py:254\u001B[0m, in \u001B[0;36mChapyter.execute_chat\u001B[0;34m(self, message, args, shell, **kwargs)\u001B[0m\n\u001B[1;32m    251\u001B[0m program \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_program(args, chatonly\u001B[38;5;241m=\u001B[39mkwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mchatonly\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m))\n\u001B[1;32m    252\u001B[0m llm \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_load_model(args, program)\n\u001B[0;32m--> 254\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[43mprogram\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmessage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmessage\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    256\u001B[0m \u001B[43m    \u001B[49m\u001B[43mllm\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mllm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    257\u001B[0m \u001B[43m    \u001B[49m\u001B[43mshell\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshell\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    258\u001B[0m \u001B[43m    \u001B[49m\u001B[43msilent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    259\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    260\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    261\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m response\n",
      "File \u001B[0;32m~/Developer/Machine_Learning_Algorithms/.venv/lib/python3.12/site-packages/chapyter/programs.py:41\u001B[0m, in \u001B[0;36mChapyterAgentProgram.execute\u001B[0;34m(self, message, llm, shell, **kwargs)\u001B[0m\n\u001B[1;32m     38\u001B[0m response \u001B[38;5;241m=\u001B[39m raw_program_response\n\u001B[1;32m     40\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m name, hook \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpost_call_hooks\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m---> 41\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mhook\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     42\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresponse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     43\u001B[0m \u001B[43m        \u001B[49m\u001B[43mshell\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     44\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     45\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m response\n",
      "File \u001B[0;32m~/Developer/Machine_Learning_Algorithms/.venv/lib/python3.12/site-packages/chapyter/programs.py:142\u001B[0m, in \u001B[0;36m<lambda>\u001B[0;34m(raw_response_str, shell, **kwargs)\u001B[0m\n\u001B[1;32m    129\u001B[0m         all_converted_str\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(last_non_code_str))\n\u001B[1;32m    131\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(all_converted_str)\n\u001B[1;32m    134\u001B[0m _DEFAULT_PROGRAM \u001B[38;5;241m=\u001B[39m ChapyterAgentProgram(\n\u001B[1;32m    135\u001B[0m     guidance_program\u001B[38;5;241m=\u001B[39mdefault_coding_guidance_program,\n\u001B[1;32m    136\u001B[0m     pre_call_hooks\u001B[38;5;241m=\u001B[39m{\n\u001B[1;32m    137\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwrap_to_dict\u001B[39m\u001B[38;5;124m\"\u001B[39m: (\u001B[38;5;28;01mlambda\u001B[39;00m x, shell, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcurrent_message\u001B[39m\u001B[38;5;124m\"\u001B[39m: x})\n\u001B[1;32m    138\u001B[0m     },\n\u001B[1;32m    139\u001B[0m     post_call_hooks\u001B[38;5;241m=\u001B[39m{\n\u001B[1;32m    140\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mextract_markdown_code\u001B[39m\u001B[38;5;124m\"\u001B[39m: (\n\u001B[1;32m    141\u001B[0m             \u001B[38;5;28;01mlambda\u001B[39;00m raw_response_str, shell, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: clean_response_str(\n\u001B[0;32m--> 142\u001B[0m                 \u001B[43mraw_response_str\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcode\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[1;32m    143\u001B[0m             )\n\u001B[1;32m    144\u001B[0m         )\n\u001B[1;32m    145\u001B[0m     },\n\u001B[1;32m    146\u001B[0m )\n\u001B[1;32m    148\u001B[0m default_coding_history_guidance_program \u001B[38;5;241m=\u001B[39m guidance(\n\u001B[1;32m    149\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    150\u001B[0m \u001B[38;5;124;03m{{#system~}}\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    162\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    163\u001B[0m )\n\u001B[1;32m    164\u001B[0m \u001B[38;5;66;03m# we don't need to add the {{current_instruction}} below {{code_history}}\u001B[39;00m\n\u001B[1;32m    165\u001B[0m \u001B[38;5;66;03m# in the template above, because after executing the current chapyter cell,\u001B[39;00m\n\u001B[1;32m    166\u001B[0m \u001B[38;5;66;03m# the instruction will be added to the history already.\u001B[39;00m\n",
      "File \u001B[0;32m~/Developer/Machine_Learning_Algorithms/.venv/lib/python3.12/site-packages/guidance/_program.py:470\u001B[0m, in \u001B[0;36mProgram.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m    469\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, key):\n\u001B[0;32m--> 470\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_variables\u001B[49m\u001B[43m[\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m]\u001B[49m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'code'"
     ]
    }
   ],
   "source": ""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd8f591-e209-4dc8-be20-8271bd46040e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
